{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Mask-RCNN evaluate model. Balloon dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import tqdm\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "os.chdir('..')\r\n",
    "\r\n",
    "from samples.plates import plates\r\n",
    "from preprocess import preprocess\r\n",
    "from preprocess import augmentation as aug\r\n",
    "\r\n",
    "from model import mask_rcnn_functional\r\n",
    "import evaluating\r\n",
    "from common import utils\r\n",
    "from common import inference_utils\r\n",
    "from common.inference_utils import process_input\r\n",
    "from common.config import CONFIG\r\n",
    "# from common.inference_optimize import maskrcnn_to_onnx, modify_onnx_model\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "utils.tf_limit_gpu_memory(tf, 2000)\r\n",
    "\r\n",
    "%matplotlib inline"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs Memory limit: 2000\n",
      "Physical GPU-devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "%load_ext watermark\r\n",
    "%watermark\r\n",
    "%watermark --iversions"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Last updated: 2021-08-07T01:23:22.643410-03:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.7.5\n",
      "IPython version      : 7.23.1\n",
      "\n",
      "Compiler    : MSC v.1916 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 158 Stepping 10, GenuineIntel\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n",
      "matplotlib: 3.1.1\n",
      "tensorflow: 2.4.1\n",
      "sys       : 3.7.5 (tags/v3.7.5:5c02a39a0b, Oct 15 2019, 00:11:34) [MSC v.1916 64 bit (AMD64)]\n",
      "numpy     : 1.19.5\n",
      "tqdm      : 4.38.0\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "base_dir = r'D:\\Data\\cemex\\patentes\\maskrccnn dataset\\maskrccnn dataset 500'\r\n",
    "train_dir = base_dir\r\n",
    "val_dir = base_dir"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from common.config import CONFIG\r\n",
    "\r\n",
    "CONFIG.update(plates.COCO_CONFIG)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "eval_dataset = plates.PlateDataset(dataset_dir=base_dir,\r\n",
    "                               subset='test',\r\n",
    "                               # SegmentationDataset necessary parent attributes\r\n",
    "                               augmentation=aug.get_validation_augmentation(\r\n",
    "                                           image_size=CONFIG['img_size'],\r\n",
    "                                           normalize=CONFIG['normalization']\r\n",
    "                               ),\r\n",
    "                               **CONFIG\r\n",
    "                              )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 50930.83it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None passed to images_dir argument.\n",
      " This means that the dataset class is a child of SegmentationDataset and itsbehaviour differs from datasets created with VGG Image Annotator.\n",
      " If it is not true, please, check your class arguments carefully.\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "eval_dataloader = preprocess.DataLoader(eval_dataset,\r\n",
    "                                        shuffle=True,\r\n",
    "                                        cast_output=False,\r\n",
    "                                        return_original=True,\r\n",
    "                                         **CONFIG\r\n",
    "                                        )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dataloader DataLoader. Steps per epoch: 51\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "weights_path = os.path.join('..', 'tests', 'samples', 'balloon', \r\n",
    "                            'maskrcnn_mobilenet_ed3e7dd4c2e064d9dd92df2088834243_cp-0029.ckpt'\r\n",
    "                           )\r\n",
    "weights_path"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'../tests/samples/balloon/maskrcnn_mobilenet_ed3e7dd4c2e064d9dd92df2088834243_cp-0029.ckpt'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Loading inference graph and import weights\r\n",
    "weights_path = r'D:\\Source\\maskrcnn_tf2\\srcsrc\\logs_old\\scalars\\maskrcnn_mobilenet_c1f61e61570ae80cd3c574c008cbf226_cp-0010.ckpt'\r\n",
    "# weights_path = r\"D:\\Source\\maskrcnn_tf2\\src\\logs_old\\scalars\"\r\n",
    "\r\n",
    "inference_config = CONFIG\r\n",
    "inference_config.update({'training': False})\r\n",
    "inference_model = mask_rcnn_functional(config=inference_config)\r\n",
    "inference_model= model.load_weights(weights_path)\r\n",
    "inference_model = inference_utils.load_mrcnn_weights(model=inference_model,\r\n",
    "                                                     weights_path=weights_path,\r\n",
    "                                                     verbose=True\r\n",
    "                                                    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "os.path.dirname(weights_path)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'src\\\\logs_old\\\\scalars'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluate data on a single batch with tensorflow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def tf_mrcnn_inference(model, infer_batch, eval_batch):\r\n",
    "    \"\"\"\r\n",
    "    Args:\r\n",
    "        model: tensorflow tf.keras.Model\r\n",
    "        infer_batch: prepared data for inference\r\n",
    "        eval_batch:  ground truth data for evaluation\r\n",
    "\r\n",
    "    Returns: boxes,\r\n",
    "             class_ids, \r\n",
    "             scores, \r\n",
    "             ull_masks, \r\n",
    "             eval_gt_boxes, \r\n",
    "             eval_gt_class_ids, \r\n",
    "             eval_gt_masks\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    # Extract inference inputs from dataloader\r\n",
    "    batch_images, batch_image_meta, batch_rpn_match, batch_rpn_bbox, \\\r\n",
    "    batch_gt_class_ids, batch_gt_boxes, batch_gt_masks = infer_batch\r\n",
    "\r\n",
    "    # Extract original inputs from dataloader\r\n",
    "    eval_gt_image = eval_batch[0][0]\r\n",
    "    eval_gt_boxes = eval_batch[3][0]\r\n",
    "    eval_gt_class_ids = eval_batch[2][0]\r\n",
    "    eval_gt_masks = eval_batch[1][0]\r\n",
    "    \r\n",
    "    # Make inference\r\n",
    "    output = model([batch_images, batch_image_meta])\r\n",
    "    detections, mrcnn_probs, mrcnn_bbox, mrcnn_mask, rpn_rois, rpn_class, rpn_bbox = output\r\n",
    "\r\n",
    "    # Extract bboxes, class_ids, scores and full-size masks\r\n",
    "    boxes, class_ids, scores, full_masks = \\\r\n",
    "        utils.reformat_detections(detections=detections[0].numpy(),\r\n",
    "                                  mrcnn_mask=mrcnn_mask[0].numpy(),\r\n",
    "                                  original_image_shape=eval_gt_image.shape,\r\n",
    "                                  image_shape=batch_images[0].shape,\r\n",
    "                                  window=batch_image_meta[0][7:11]\r\n",
    "                                  )\r\n",
    "    return boxes, class_ids, scores, full_masks, eval_gt_boxes, eval_gt_class_ids, eval_gt_masks"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def evaluate_mrcnn(model, inference_function, eval_dataloader, iou_limits=(0.5, 1), iou_step=0.05):\r\n",
    "    \"\"\"\r\n",
    "    Evaluate Mask-RCNN model\r\n",
    "    Args:\r\n",
    "        model: tensorflow tf.keras.Model\r\n",
    "        inference_function:\r\n",
    "        eval_dataloader:\r\n",
    "        iou_limits: start and end for IoU in mAP\r\n",
    "        iou_step:   step for IoU in mAP\r\n",
    "\r\n",
    "    Returns:\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    # Evaluate mAP\r\n",
    "    for eval_iou_threshold in np.arange(iou_limits[0], iou_limits[1], iou_step):\r\n",
    "\r\n",
    "        # Metrics lists\r\n",
    "        ap_list = []\r\n",
    "        precisions_list = []\r\n",
    "        recalls_list = []\r\n",
    "\r\n",
    "        eval_iterated = iter(eval_dataloader)\r\n",
    "        pbar = tqdm.tqdm(eval_iterated, total=eval_dataloader.__len__())\r\n",
    "\r\n",
    "        for eval_input, _ in pbar:\r\n",
    "            # Split batch into prepared data for inference and original data for evaluation\r\n",
    "            infer_batch = eval_input[:-4]\r\n",
    "            eval_batch = eval_input[-4:]\r\n",
    "            \r\n",
    "            try:\r\n",
    "                boxes, class_ids, scores, full_masks, eval_gt_boxes, eval_gt_class_ids, eval_gt_masks = \\\r\n",
    "                    inference_function(model=model, infer_batch=infer_batch, eval_batch=eval_batch)\r\n",
    "\r\n",
    "                # Get AP, precisions, recalls, overlaps\r\n",
    "                ap, precisions, recalls, overlaps = \\\r\n",
    "                    evaluating.compute_ap(gt_boxes=eval_gt_boxes,\r\n",
    "                                          gt_class_ids=eval_gt_class_ids,\r\n",
    "                                          gt_masks=eval_gt_masks,\r\n",
    "                                          pred_boxes=boxes,\r\n",
    "                                          pred_class_ids=class_ids,\r\n",
    "                                          pred_scores=scores,\r\n",
    "                                          pred_masks=full_masks,\r\n",
    "                                          iou_threshold=eval_iou_threshold\r\n",
    "                                          )\r\n",
    "                postfix = ''\r\n",
    "            except:\r\n",
    "                postfix = 'Passed an image. AP added as zero.'\r\n",
    "                ap = 0.0\r\n",
    "                precisions = 0.0\r\n",
    "                recalls = 0.0\r\n",
    "            \r\n",
    "            ap_list.append(ap)\r\n",
    "            precisions_list.append(precisions)\r\n",
    "            recalls_list.append(recalls)\r\n",
    "\r\n",
    "            # Update tqdm mAP\r\n",
    "            pbar.set_description(f\"IoU: {eval_iou_threshold:.2f}. mAP: {np.mean(ap_list):.4f} \")# {postfix}\r\n",
    "\r\n",
    "\r\n",
    "        print(f'mAP={np.mean(ap_list):.4f}, IoU: {eval_iou_threshold:.2f}')"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "evaluate_mrcnn(model=inference_model,\n",
    "               inference_function=tf_mrcnn_inference,\n",
    "               eval_dataloader=eval_dataloader\n",
    "              )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.50. mAP: 0.4469 : 100%|██████████| 13/13 [00:07<00:00,  1.67it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.4469, IoU: 0.50\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.55. mAP: 0.4084 : 100%|██████████| 13/13 [00:05<00:00,  2.19it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.4084, IoU: 0.55\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.60. mAP: 0.4084 : 100%|██████████| 13/13 [00:05<00:00,  2.18it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.4084, IoU: 0.60\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.65. mAP: 0.3853 : 100%|██████████| 13/13 [00:06<00:00,  2.16it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.3853, IoU: 0.65\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.70. mAP: 0.3725 : 100%|██████████| 13/13 [00:06<00:00,  2.14it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.3725, IoU: 0.70\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.75. mAP: 0.2930 : 100%|██████████| 13/13 [00:06<00:00,  2.16it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.2930, IoU: 0.75\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.80. mAP: 0.2161 : 100%|██████████| 13/13 [00:06<00:00,  2.13it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.2161, IoU: 0.80\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.85. mAP: 0.1802 : 100%|██████████| 13/13 [00:06<00:00,  2.15it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.1802, IoU: 0.85\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.90. mAP: 0.1033 : 100%|██████████| 13/13 [00:06<00:00,  2.12it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.1033, IoU: 0.90\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.95. mAP: 0.0000 : 100%|██████████| 13/13 [00:06<00:00,  2.13it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.0000, IoU: 0.95\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluate data on a single batch with TensorRT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def trt_mrcnn_inference(model, infer_batch, eval_batch):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        model: tensorflow tf.keras.Model\n",
    "        infer_batch: prepared data for inference\n",
    "        eval_batch:  ground truth data for evaluation\n",
    "\n",
    "    Returns: boxes,\n",
    "             class_ids, \n",
    "             scores, f\n",
    "             ull_masks, \n",
    "             eval_gt_boxes, \n",
    "             eval_gt_class_ids, \n",
    "             eval_gt_masks\n",
    "\n",
    "    \"\"\"\n",
    "    # Extract inference inputs from dataloader\n",
    "    batch_images, batch_image_meta, batch_rpn_match, batch_rpn_bbox, \\\n",
    "    batch_gt_class_ids, batch_gt_boxes, batch_gt_masks = infer_batch\n",
    "\n",
    "    # Extract original inputs from dataloader\n",
    "    eval_gt_image = eval_batch[0][0]\n",
    "    eval_gt_boxes = eval_batch[3][0]\n",
    "    eval_gt_class_ids = eval_batch[2][0]\n",
    "    eval_gt_masks = eval_batch[1][0]\n",
    "\n",
    "    # Extract trt-variables from a dict for transparency\n",
    "    engine = model['engine']\n",
    "    stream = model['stream']\n",
    "    context = model['context']\n",
    "    device_input = model['device_input']\n",
    "    device_output1 = model['device_output1']\n",
    "    device_output2 = model['device_output2']\n",
    "\n",
    "    host_output1 = model['host_output1']\n",
    "    host_output2 = model['host_output2']\n",
    "    \n",
    "    output_nodes = model['output_nodes']\n",
    "    graph_type = model['graph_type']\n",
    "    \n",
    "    \n",
    "    if graph_type == 'uff':\n",
    "        # Prepare image for uff original graph\n",
    "        input_image, window, scale, padding, crop = utils.resize_image(\n",
    "                eval_gt_image,\n",
    "                min_dim=800,\n",
    "                min_scale=0,\n",
    "                max_dim=1024,\n",
    "                mode='square')\n",
    "        #  Substract channel-mean\n",
    "        input_image = input_image.astype(np.float32) - np.array([123.7, 116.8, 103.9])\n",
    "        \n",
    "        image_shape_reformat = input_image.shape\n",
    "        \n",
    "        # Add batch dimension\n",
    "        batch_images = np.expand_dims(input_image, 0)\n",
    "        # (batch, w, h, 3) -> (batch, 3, w, h)\n",
    "        batch_images = np.moveaxis(batch_images, -1, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        window = batch_image_meta[0][7:11]\n",
    "        image_shape_reformat = batch_images[0].shape\n",
    "\n",
    "    # Make inference\n",
    "    host_input = batch_images.astype(dtype=np.float32, order='C')\n",
    "    cuda.memcpy_htod_async(device_input, host_input, stream)\n",
    "    context.execute_async(bindings=[int(device_input),\n",
    "                                    int(device_output1),\n",
    "                                    int(device_output2),\n",
    "                                    ],\n",
    "                          stream_handle=stream.handle)\n",
    "\n",
    "    cuda.memcpy_dtoh_async(host_output1, device_output1, stream)\n",
    "    cuda.memcpy_dtoh_async(host_output2, device_output2, stream)\n",
    "    stream.synchronize()\n",
    "    \n",
    "    output_shape1 = engine.get_binding_shape(output_nodes[0])\n",
    "    output_shape2 = engine.get_binding_shape(output_nodes[1])\n",
    "    \n",
    "    if graph_type == 'onnx':\n",
    "        trt_mrcnn_detection = host_output1.reshape(output_shape1).astype(dtype=np.float32)\n",
    "        trt_mrcnn_mask = host_output2.reshape(output_shape2).astype(dtype=np.float32)\n",
    "    elif graph_type == 'uff':\n",
    "        # (batch, 100, 6)\n",
    "        trt_mrcnn_detection = host_output1.reshape(\n",
    "            (engine.max_batch_size, *output_shape1)).astype(dtype=np.float32)\n",
    "        # (batch, 100, 2, 28, 28)\n",
    "        trt_mrcnn_mask = host_output2.reshape(\n",
    "            (engine.max_batch_size, *output_shape2)).astype(dtype=np.float32)\n",
    "        # (batch, 100, 2, 28, 28) -> (batch, 100, 28, 28, 2)\n",
    "        trt_mrcnn_mask = np.moveaxis(trt_mrcnn_mask, 2, -1)\n",
    "    else:\n",
    "        raise ValueError(f'Only onnx and uff graph types. Passed: {graph_type}')\n",
    "        \n",
    "\n",
    "    # Extract bboxes, class_ids, scores and full-size masks\n",
    "    trt_boxes, trt_class_ids, trt_scores, trt_full_masks = \\\n",
    "        utils.reformat_detections(detections=trt_mrcnn_detection[0],\n",
    "                                  mrcnn_mask=trt_mrcnn_mask[0],\n",
    "                                  original_image_shape=eval_gt_image.shape,\n",
    "                                  image_shape=image_shape_reformat,\n",
    "                                  window=window\n",
    "                                  )\n",
    "    \n",
    "    return trt_boxes, trt_class_ids, trt_scores, trt_full_masks, eval_gt_boxes, eval_gt_class_ids, eval_gt_masks"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def set_mrcnn_trt_engine(model_path, output_nodes=['mrcnn_detection', 'mrcnn_mask'], graph_type='onnx'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Load TensorRT engine via pycuda\n",
    "    Args:\n",
    "        model_path: model path to TensorRT-engine\n",
    "        output_nodes: output nodes names\n",
    "        graph_type: onnx or uff\n",
    "\n",
    "    Returns: python dict of attributes for pycuda model inference\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    trt_logger = trt.Logger(trt.Logger.VERBOSE)\n",
    "    trt.init_libnvinfer_plugins(trt_logger, \"\")\n",
    "\n",
    "    with open(model_path, \"rb\") as f, trt.Runtime(trt_logger) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    # Inputs\n",
    "    input_shape = engine.get_binding_shape('input_image')\n",
    "    input_size = trt.volume(input_shape) *\\\n",
    "                 engine.max_batch_size * np.dtype(np.float32).itemsize\n",
    "    device_input = cuda.mem_alloc(input_size)\n",
    "\n",
    "    # Outputs\n",
    "    output_names = list(engine)[1:]\n",
    "\n",
    "    # mrcnn_detection output\n",
    "    output_shape1 = engine.get_binding_shape(output_nodes[0])\n",
    "    host_output1 = cuda.pagelocked_empty(trt.volume(output_shape1) *\n",
    "                                              engine.max_batch_size,\n",
    "                                              dtype=np.float32)\n",
    "    device_output1 = cuda.mem_alloc(host_output1.nbytes)\n",
    "\n",
    "\n",
    "    # mrcnn_mask output\n",
    "    output_shape2 = engine.get_binding_shape(output_nodes[1])\n",
    "    host_output2 = cuda.pagelocked_empty(trt.volume(output_shape2) * engine.max_batch_size,\n",
    "                                              dtype=np.float32)\n",
    "    device_output2 = cuda.mem_alloc(host_output2.nbytes)\n",
    "\n",
    "    # Setting a cuda stream\n",
    "    stream = cuda.Stream()\n",
    "    \n",
    "    return {'engine': engine,\n",
    "            'stream': stream,\n",
    "            'context': context,\n",
    "            'device_input': device_input,\n",
    "            'device_output1': device_output1,\n",
    "            'device_output2':device_output2,\n",
    "            'host_output1': host_output1,\n",
    "            'host_output2': host_output2,\n",
    "            'output_nodes': output_nodes,\n",
    "            'graph_type': graph_type\n",
    "           }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "evaluate_mrcnn(model=set_mrcnn_trt_engine(\n",
    "    model_path=f\"\"\"../weights/maskrcnn_{CONFIG['backbone']}_512_512_3_trt_mod_fp32.engine\"\"\"),\n",
    "               inference_function=trt_mrcnn_inference,\n",
    "               eval_dataloader=eval_dataloader\n",
    "              )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.50. mAP: 0.2013 : 100%|██████████| 13/13 [00:04<00:00,  2.61it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.2013, IoU: 0.50\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.55. mAP: 0.1859 : 100%|██████████| 13/13 [00:04<00:00,  2.90it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.1859, IoU: 0.55\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.60. mAP: 0.1859 : 100%|██████████| 13/13 [00:04<00:00,  2.94it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.1859, IoU: 0.60\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.65. mAP: 0.1538 : 100%|██████████| 13/13 [00:04<00:00,  2.91it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.1538, IoU: 0.65\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.70. mAP: 0.0000 : 100%|██████████| 13/13 [00:04<00:00,  2.87it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.0000, IoU: 0.70\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.75. mAP: 0.0000 : 100%|██████████| 13/13 [00:04<00:00,  2.94it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.0000, IoU: 0.75\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.80. mAP: 0.0000 : 100%|██████████| 13/13 [00:04<00:00,  2.90it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.0000, IoU: 0.80\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.85. mAP: 0.0000 : 100%|██████████| 13/13 [00:04<00:00,  2.94it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.0000, IoU: 0.85\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.90. mAP: 0.0000 : 100%|██████████| 13/13 [00:04<00:00,  2.90it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.0000, IoU: 0.90\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IoU: 0.95. mAP: 0.0000 : 100%|██████████| 13/13 [00:04<00:00,  2.96it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP=0.0000, IoU: 0.95\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "evaluate_mrcnn(model=set_mrcnn_trt_engine(\n",
    "    model_path=f\"\"\"../weights/maskrcnn_{CONFIG['backbone']}_512_512_3_trt_mod_fp16.engine\"\"\"),\n",
    "               inference_function=trt_mrcnn_inference,\n",
    "               eval_dataloader=eval_dataloader\n",
    "              )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "interpreter": {
   "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}